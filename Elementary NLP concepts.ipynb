{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This talk covers\n",
    "* Term Frequency (i.e. vectorized text)\n",
    "* Stop words\n",
    "* Term Frequency - Inverse Document Frequency (TF-IDF)\n",
    "* Negation Marking\n",
    "* NGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term frequency (i.e. vectorized text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"I liked the movie, just not the popcorn.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>just</th>\n",
       "      <th>liked</th>\n",
       "      <th>movie</th>\n",
       "      <th>not</th>\n",
       "      <th>popcorn</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   just  liked  movie  not  popcorn  the\n",
       "0   1.0    1.0    1.0  1.0      1.0  2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=False, norm=None)\n",
    "vectorizer.fit(docs)\n",
    "\n",
    "pd.DataFrame(vectorizer.transform(docs).toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Note: \"I\" is missing because the default tokenizer omits one letter words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>just</th>\n",
       "      <th>liked</th>\n",
       "      <th>movie</th>\n",
       "      <th>popcorn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   just  liked  movie  popcorn\n",
       "0   1.0    1.0    1.0      1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=False, norm=None, stop_words='english')\n",
    "vectorizer.fit(docs)\n",
    "\n",
    "pd.DataFrame(vectorizer.transform(docs).toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Note \"the\" and \"not\" considered stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency - Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"I liked the movie, just not the popcorn.\",\n",
    "    \"I liked the song, just not the words.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>just</th>\n",
       "      <th>liked</th>\n",
       "      <th>movie</th>\n",
       "      <th>popcorn</th>\n",
       "      <th>song</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   just  liked  movie  popcorn  song  words\n",
       "0   1.0    1.0    1.0      1.0   0.0    0.0\n",
       "1   1.0    1.0    0.0      0.0   1.0    1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=False, norm=None, stop_words='english')\n",
    "vectorizer.fit(docs)\n",
    "\n",
    "pd.DataFrame(vectorizer.transform(docs).toarray(),\n",
    "             columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Note: \"I\" is missing because the default tokenizer omits one letter words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>just</th>\n",
       "      <th>liked</th>\n",
       "      <th>movie</th>\n",
       "      <th>popcorn</th>\n",
       "      <th>song</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>1.405465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   just  liked     movie   popcorn      song     words\n",
       "0   1.0    1.0  1.405465  1.405465  0.000000  0.000000\n",
       "1   1.0    1.0  0.000000  0.000000  1.405465  1.405465"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True, norm=None, stop_words='english')\n",
    "vectorizer.fit(docs)\n",
    "\n",
    "pd.DataFrame(vectorizer.transform(docs).toarray(),\n",
    "             columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Note: \"I\" is missing because the default tokenizer omits one letter words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negation Marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"I liked the movie, just not the popcorn.\",\n",
    "    \"I liked the popcorn, just not the movie.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without negation marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>just</th>\n",
       "      <th>liked</th>\n",
       "      <th>movie</th>\n",
       "      <th>popcorn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   just  liked  movie  popcorn\n",
       "0   1.0    1.0    1.0      1.0\n",
       "1   1.0    1.0    1.0      1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=False, norm=None,\n",
    "                             stop_words='english') # Note: no TF-IDF\n",
    "vectorizer.fit(docs)\n",
    "\n",
    "pd.DataFrame(vectorizer.transform(docs).toarray(),\n",
    "             columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With negation marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I liked the movie , just not the_NEG popcorn_NEG .',\n",
       " 'I liked the popcorn , just not the_NEG movie_NEG .']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.util import mark_negation\n",
    "\n",
    "negation_marked_docs = [' '.join(mark_negation(word_tokenize(doc)))\n",
    "                            for doc in docs]\n",
    "negation_marked_docs\n",
    "\n",
    "# Note \"the_NEG\" which is here because this hack doesn't account for stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>just</th>\n",
       "      <th>liked</th>\n",
       "      <th>movie</th>\n",
       "      <th>movie_neg</th>\n",
       "      <th>popcorn</th>\n",
       "      <th>popcorn_neg</th>\n",
       "      <th>the_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   just  liked  movie  movie_neg  popcorn  popcorn_neg  the_neg\n",
       "0   1.0    1.0    1.0        0.0      0.0          1.0      1.0\n",
       "1   1.0    1.0    0.0        1.0      1.0          0.0      1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=False, norm=None,\n",
    "                             stop_words='english')\n",
    "vectorizer.fit(negation_marked_docs)\n",
    "\n",
    "pd.DataFrame(vectorizer.transform(negation_marked_docs).toarray(),\n",
    "             columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"I liked the movie, just not the popcorn.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character NGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u' j',\n",
       " u' l',\n",
       " u' m',\n",
       " u' n',\n",
       " u' p',\n",
       " u' t',\n",
       " u', ',\n",
       " u'co',\n",
       " u'd ',\n",
       " u'e ',\n",
       " u'e,',\n",
       " u'ed',\n",
       " u'he',\n",
       " u'i ',\n",
       " u'ie',\n",
       " u'ik',\n",
       " u'ju',\n",
       " u'ke',\n",
       " u'li',\n",
       " u'mo',\n",
       " u'n.',\n",
       " u'no',\n",
       " u'op',\n",
       " u'or',\n",
       " u'ot',\n",
       " u'ov',\n",
       " u'pc',\n",
       " u'po',\n",
       " u'rn',\n",
       " u'st',\n",
       " u't ',\n",
       " u'th',\n",
       " u'us',\n",
       " u'vi']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=False, norm=None,\n",
    "                             ngram_range=(2,2), analyzer='char')\n",
    "vectorizer.fit(docs)\n",
    "\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>t</th>\n",
       "      <th>,</th>\n",
       "      <th>co</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>ot</th>\n",
       "      <th>ov</th>\n",
       "      <th>pc</th>\n",
       "      <th>po</th>\n",
       "      <th>rn</th>\n",
       "      <th>st</th>\n",
       "      <th>t</th>\n",
       "      <th>th</th>\n",
       "      <th>us</th>\n",
       "      <th>vi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     j    l    m    n    p    t   ,    co   d    e  ...    ot   ov   pc   po  \\\n",
       "0  1.0  1.0  1.0  1.0  1.0  2.0  1.0  1.0  1.0  2.0 ...   1.0  1.0  1.0  1.0   \n",
       "\n",
       "    rn   st   t    th   us   vi  \n",
       "0  1.0  1.0  2.0  2.0  1.0  1.0  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vectorizer.transform(docs).toarray(),\n",
    "             columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word NGrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word bigrams (N=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>just popcorn</th>\n",
       "      <th>liked movie</th>\n",
       "      <th>movie just</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   just popcorn  liked movie  movie just\n",
       "0           1.0          1.0         1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=False, norm=None,\n",
    "                             stop_words='english', ngram_range=(2,2))\n",
    "vectorizer.fit(docs)\n",
    "\n",
    "pd.DataFrame(vectorizer.transform(docs).toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word trigrams N=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked movie just</th>\n",
       "      <th>movie just popcorn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked movie just  movie just popcorn\n",
       "0               1.0                 1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=False, norm=None,\n",
    "                             stop_words='english', ngram_range=(3,3))\n",
    "vectorizer.fit(docs)\n",
    "\n",
    "pd.DataFrame(vectorizer.transform(docs).toarray(), columns=vectorizer.get_feature_names())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
